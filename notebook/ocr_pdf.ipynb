{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pdfの論文を全部OCRで文字起こしするためのコード\n",
    "## （表などあると汚くなるので微妙...）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from google.cloud import storage\n",
    "from google.cloud import vision_v1p2beta1 as vision\n",
    "from google.protobuf import json_format\n",
    "\n",
    "from time import sleep\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def async_detect_document(gcs_source_uri, gcs_destination_uri):\n",
    "    # Supported mime_types are: 'application/pdf' and 'image/tiff'\n",
    "    mime_type = 'application/pdf'\n",
    "\n",
    "    # How many pages should be grouped into each json output file.\n",
    "    # With a file of 5 pages\n",
    "    #batch_size = 2\n",
    "    batch_size = 5\n",
    "\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    feature = vision.types.Feature(\n",
    "        type=vision.enums.Feature.Type.DOCUMENT_TEXT_DETECTION)\n",
    "\n",
    "    gcs_source = vision.types.GcsSource(uri=gcs_source_uri)\n",
    "    input_config = vision.types.InputConfig(\n",
    "        gcs_source=gcs_source, mime_type=mime_type)\n",
    "\n",
    "    gcs_destination = vision.types.GcsDestination(uri=gcs_destination_uri)\n",
    "    output_config = vision.types.OutputConfig(\n",
    "        gcs_destination=gcs_destination, batch_size=batch_size)\n",
    "\n",
    "    async_request = vision.types.AsyncAnnotateFileRequest(\n",
    "        features=[feature], input_config=input_config,\n",
    "        output_config=output_config)\n",
    "\n",
    "    operation = client.async_batch_annotate_files(\n",
    "        requests=[async_request])\n",
    "\n",
    "    print(\"Operation started: {}\".format(operation.operation))\n",
    "\n",
    "    return operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kanouchishin/py3.7/lib/python3.7/site-packages/google/auth/_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation started: name: \"projects/usable-auth-library/operations/30da48c8eccc9bc0\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gcs_source_uri = \"gs://work_kanouchi/ocr/in/A1-1.pdf\"\n",
    "gcs_destination_uri = \"gs://work_kanouchi/ocr/out/A1-1\"\n",
    "req= async_detect_document(gcs_source_uri, gcs_destination_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<google.api_core.operation.Operation object at 0x10b0d7748>\n"
     ]
    }
   ],
   "source": [
    "print(req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wait_time = 15\n",
    "sleep(wait_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "while (True):\n",
    "    if req.done():\n",
    "        break\n",
    "\n",
    "    print(\"Operation not completed. Stil waiting...\")\n",
    "    sleep(wait_time)\n",
    "    wait_time += 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kanouchishin/py3.7/lib/python3.7/site-packages/google/auth/_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/Users/kanouchishin/py3.7/lib/python3.7/site-packages/google/auth/_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "storage_client = storage.Client()\n",
    "blob_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = re.match(r'gs://([^/]+)/(.+)', gcs_destination_uri)\n",
    "\n",
    "if match :\n",
    "\n",
    "    bucket_name = match.group(1)\n",
    "    prefix = match.group(2)\n",
    "\n",
    "    bucket = storage_client.get_bucket(bucket_name=bucket_name)\n",
    "\n",
    "    # List objects with the given prefix.\n",
    "    blob_list = list(bucket.list_blobs(prefix=prefix))\n",
    "    \n",
    "else:\n",
    "    print(\"Pattern not matched!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output files:\n",
      "ocr/out/A1-1output-1-to-4.json\n"
     ]
    }
   ],
   "source": [
    "print('Output files:')\n",
    "\n",
    "\n",
    "for blob in blob_list:\n",
    "    print(blob.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = blob_list[0]\n",
    "\n",
    "json_string = output.download_as_string()\n",
    "\n",
    "response = json_format.Parse(\n",
    "    json_string, vision.types.AnnotateFileResponse())\n",
    "\n",
    "# The actual response for the first page of the input file.\n",
    "first_page_response = response.responses[0]\n",
    "annotation = first_page_response.full_text_annotation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(u'Full text:\\n{}'.format(\n",
    "    annotation.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"言語処理学会 第25回年次大会 発表論文集(2019年3月)\\n日本語から英語への文脈翻訳テストの提案\\n永田 昌明 森下睦\\nNTT コミュニケーション科学基礎研究所\\n{nagata.masaaki, morishita.makoto}@lab.ntt.co.jp\\n1 はじめに\\nとなる連続する2つの英語文を作成した。さらに、正解\\nと対照可能な不正解として、英語の第2文に対して文\\n脈を考慮しないことにより生じる必要最小限の誤りを\\n加えた英語文を作成した。この際、できるだけ正解率\\nが50%になるよう工夫した。ここで考慮する文脈情報\\nは共参照 (coreference) と一貫性 (coherence/cohesion)\\nとし、その総数は約 1000件である。\\n2.1 共参照\\nニューラル機械翻訳の登場により文単位の翻訳精度\\nは大きく向上し、さらに翻訳精度を上げるために文脈\\nを利用する研究が始まった [15, 1, 17] 。文脈を利用す\\nる最も簡単な方法は、原言語および目的言語において\\n直前の文と現在の文を <concat> のような特別な区切\\nり記号で連結し、通常の文単位の翻訳を行うことでで\\nある [15]。この方法は 2-to-2 と呼ばれ、最先端の文脈\\n翻訳手法と大差ない精度が得られることが知られてい\\nる [1, 17]。これに対して通常の文単位の翻訳は 1-to-1\\nと呼ばれる。また入力文と文脈に別々の encoder を使\\n用する方法も提案されており、encoder として RNN[1]\\nや transformer[17] が使われている。\\n文脈の利用法を関する研究の問題点の一つは、BLEU\\nのような従来の自動評価尺度では、文脈の何が問題で\\nそれが提案手法によりどう改善されたのかよくわか\\nらないことである。文献 [1] では、対照テストセット\\n(contrastive test set)[11] の枠組みに基づいて、英語\\nからフランス語への翻訳において機械翻訳が文脈を理\\n解して適切な訳文を生成する能力を評価する文脈テス\\nトセットを提案した\\n本稿では日本語から英語への翻訳の文脈テストの作\\n成法を提案する。我々は当初、文献 [1] の方法に基づ\\nいて共参照と一貫性に関する文脈テストを作成しよう\\nとしたが、文脈処理の対象となる問題は言語対および\\n翻訳方法に大きく依存するため、試行錯誤の結果、全\\nく別の方法に辿り着いた。以下では、まず日英文脈翻\\n訳テストセットの概要を述べ、これを用いて 2-to-2 に\\nよる日英文脈翻訳を分析した結果を報告する。\\nSource:\\nContext: 申し訳ありませんが、先生は午後少し遅れ\\nているんです。\\nInput: (*pro* が)診察するまでに 20分ほどかかる\\nと思います。\\nTarget:\\nContext: I'm afraid that the doctor is running a bit\\nlate this afternoon.\\nCorrect: It might be about 20 minutes before he\\ncan see you.\\nIncorrect: It might be about 20 minutes before we\\ncan see you.\\n(a) ゼロ代名詞\\nSource:\\nContext: ・ソファのそばには木製の椅子がある。\\nInput: レンズとピンセットが椅子に乗っている。\\nTarget:\\nContext: Beside the couch was a wooden chair.\\nCorrect: A lens and a forceps was lying upon\\nthe seat.\\nIncorrect: A lens and a forceps was lying upon\\na seat.\\n(b) 冠詞\\n図 1: 共参照に関するテスト\\n2 文脈翻訳の対照テスト\\n日本語から英語への文脈翻訳テストとして、日本語\\nの第1文に依存して日本語の第2文の英語訳が決定さ\\nれるような連続する2つの日本語文、および、その翻訳\\n共参照については、日本語のゼロ代名詞と英語の冠\\n詞に関するテストを作成した。これらは目的言語に対\\n応する原言語の言語要素が存在しないので、基本的に\\n文脈に依存して生成される。\\n日本語では文脈から了解できる主語や目的語は省略\\n-\\n1-\\nCopyright(C) 2019 The Association for Natural Language Processing.\\nAll Rights Reserved.\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "filename = \"/Users/kanouchishin/Downloads/ocr_out_output-1-to-4.json\"\n",
    "fp = open(filename)\n",
    "data = json.load(fp)\n",
    "data['responses'][0]['fullTextAnnotation']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"We aren't allowed to use a (*the) mobile\\nphone in class.\\n照応関係があり、一方がaで他方が the であるような\\n英語文のデータ OnteNotes の coreference chain から\\n容易に見つけることができる。\\n2.2 一貫性\\n昨日、渋谷へ行った。\\nすごい人だった。\\nSource:\\nContext:\\nInput:\\nTarget:\\nContext:\\nCorrect:\\nIncorrect:\\nI went to Shibuya yesterday.\\nThere are a lot of people.\\nHe is a great man.\\n(a) 曖昧性解消\\nいい時計ですね。\\nこの時計は父の形見なんです。\\nSource:\\nContext:\\nInput:\\nTarget:\\nContext:\\nCorrect:\\nIncorrect:\\nIt's a nice clock.\\nThis clock is a memento of my father.\\nThis watch is a memento of my father.\\nされる。それに対して英語は構文上の制約から主語や\\n目的語が必須である。そのため英語側の代名詞の人称、\\n数、格を正しく決定しなければならない。図 1(a) の\\n例では、文脈がなければ「思う」のような思考動詞や\\n「診察する」のような意思を伴う行為動詞のデフォー\\nルトの主語は一人称であるが、ここでは前の文に登場\\nする人物を指していることから正解は三人称になる。\\n文献 [1] では、OpenSubtities にある実例を参考に\\nして文脈テストを作成している。当初、我々も Open-\\nSubtitles や Ted Talk のコーパスからテストを作成し\\nようとしたが、日本語のゼロ代名詞のデフォールト訳\\nが一人称または二人称であることが多いという視点が\\n欠け、不自然になることが多かった。また日本人の作\\n業者でも、ゼロ代名詞を正しく分析するのは難しく、\\n作業誤りが目立った。\\nそこでまず信頼できるゼロ代名詞の分析結果とし\\nて Keyaki Treebank[2] を用いることにした。具体的\\nには、まず日本語のゼロ代名詞 (*pro*) を含む文を選\\n択し、これを Google 翻訳等の機械翻訳にかけて、デ\\nフォールトのゼロ代名詞の英語訳 (正解訳) を確認す\\nる。次に不正解となる英語の代名詞 (不正解訳) を選\\nび、正解訳が正解となり不正解訳が不正解となるよう\\nな先行文脈と、正解訳が不正解になり不正解訳が正解\\nになる先行文脈を作成した。同時に2つのテストを作\\n成することで正解率を 50%にすることができる。\\n図 1() に冠詞のテストの例を示す。日本語側で第\\n1文と第2文で「椅子」に言及しているので、英語側\\nの第2文では定冠詞 the が使われている。日本語側\\nの「椅子」に対して英語側は表層形が異なり (chair と\\nseat)、橋渡し参照 (bridge reference) になっている。\\n我々は冠詞の定/不定に関して先行文に(橋渡しも含\\nめて) 先行詞がある場合と先行文に指示対象がないダ\\nミーの先行文が半々になるようにテストを作成した。\\n対訳コーパスから冠詞の定/不定の例を探すの\\nは効率が悪いので、文法誤り訂正のテストセット\\nHOO-2012[4] と共参照解析の注釈つきのコーパス\\nOnteNotes5.0[5] を使用した。自然性が高いダミーの\\n先行文を作成するのは非常に難しいので、文法誤り訂\\n正の正解データにおいて the から aへ訂正されている\\n以下の例のような文は、照応関係が成立しない文を作\\n成するのに有益であった。\\n(b) 対応\\n図 2: 一貫性に関するテスト\\n一貫性に関しては言語に依存する部分が少ないので、\\n文献 [1] に従って曖昧性解消 (disambiguation) と対応\\n(alignment/repetition) のテストを作成した。\\n図2(a) に曖昧性解消のテストの例を示す。「すごい」\\nには「多く」と「偉大な」という2つの語義があり、\\n訳し分けに文脈が必要である。一般に曖昧性に関する\\nテストは以下の3つの条件を満たす。\\n・ 原言語文は多義 (曖昧性) を持つ語句を含む。\\n・ その多義は目的言語の異なる語句に翻訳される。\\n・原言語または目的言語の先行文によってどちらの\\n訳を使うかが決まる。\\n当初、対訳データから上記の条件にあてはまるものを\\n探そうしたが、日本語は同じ発音でも意味が異なる場\\n合には違う漢字を使うので、英訳が複数ある日本語の\\n単語は少ない。そこで我々は複数の日英辞書から上記\\nの条件を満たす単語を選定し、ゼロから人手でテスト\\nを作成した。ちなみに英日翻訳の場合には、日本語が\\n多義になるものが多いので、このテストの作り易さは\\n言語対だけではなく翻訳方向に依存する。\\nIn our country, there are rules that everyone\\nhas to follow, and recently a new rule was\\nadded.\\n-\\n2-\\nCopyright(C) 2019 The Association for Natural Language Processing.\\nAll Rights Reserved.\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['responses'][1]['fullTextAnnotation']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'図 2(b) に対応に関するテストの例を示す。時計の\\n英訳は clock または watch であるが、同一文脈で同一\\n対象を指示する際に2つの訳が混在してはいけない。\\n一般に一貫性に関するテストは以下の3つの条件を満\\nたす。\\nDataset\\nIWSLT2017\\n(TED Talks)\\nlen(ja)\\n22.3\\n21.8\\n22.5\\n7.6\\n9.0\\n・ 原言語文は多義を持つ語句を含む。\\nOpenSubtitles2018\\n(movie subtitles)\\n6.9\\n・ その多義は目的言語の異なる語句に翻訳される。\\n目的言語ではこれらはほとんど別概念なので、相\\n互に入れ替えることは不可能である。\\nGlobal Voices\\n(blog)\\ntest\\n・ 原言語の先行文でも同じ語句単語を含み、当該語\\n句の意味の違いに応じて、目的言語では現在の文\\nと同じ多義が生じる。\\nlen(en)\\n20.6\\n19.1\\n19.5\\n8.5\\n7.7\\n8.9\\n21.6\\n22.0\\n21.8\\n22.0\\n20.3\\n21.3\\n21.1\\n19.8\\n19.9\\n14.9\\n15.1\\n13.1\\n24.9\\nHiragana Times\\nBooks\\n(book)\\nHiraganaTimes\\n(magazine)\\nSplit sents\\ntrain 218,174\\ndev 2,577\\ntest 2,357\\ntrain 2,077,430\\ndev 3,245\\ntest\\n2,901\\ntrain 29,508\\ndev\\n9,426\\n8,148\\ntrain 16,472\\ndev 2,792\\ntest\\ntrain 189,925\\ndev 5,385\\ntest 5,004\\ntrain 103,417\\ndev 4,279\\n3,212\\ntrain 480,778\\n1,257\\ntest\\n1,287\\ntrain 283,710\\ndev\\n3,002\\n3,014\\ntrain | 3,399,414\\ndev 31,963\\ntest | | 28,460\\n2,537\\n目的言語ではほぼ別概念なので、先行文と同じ語句を\\n使う必要があるという制約は、言語対や翻訳方向によ\\nらない一般的な問題である。ここでどの語句が正解訳\\nかは言語表現と実世界との対応 (grounding) で決まる\\nが、これは本テストの対象外とする。\\n27.8\\n28.4\\n28.1\\n24.6\\n22.4\\n23.4\\n24.7\\n21.3\\n21.1\\n20.5\\n21.0\\n17.8\\n23.4\\n20.2\\n21.3\\n27.2\\n23.3\\n24.3\\n14.0\\n22.4\\n22.0\\nNICT_align\\n(book)\\ntest\\nWikipedia Kyoto\\n(Wikipedia)\\ndev\\n19.9\\nYomiuri editorial\\n(newspaper\\neditorials)\\n21.7\\n28.2\\n24.8\\n26.4\\ntest\\n3 実験\\n3.1 データとツール\\nAll\\n14.3\\n19.1\\n19.4\\n表1: 日英対訳データに関する統計量\\n文脈翻訳の実験に使用した日英対訳データを表1\\nに示す。訓練データは約 340 万文、開発データと\\nテストデータはそれぞれ約3 万文である。このう\\nち OpenSubtitles2018[7], IWSLT-2017[3] は話し言\\n葉、Global Voices[10], Wikipedia 日英京都関連文書\\n(KFTT)1, 日英対訳文対応付けデータ [16], ひらがな\\nタイムズ, 読売新聞社説は書き言葉である。\\n英語文は Moses toolkit を用いて字句解析および\\n小文字化し、日本語文は NFKC 正規化して MeCab\\nUniDic で単語分割した。さらに英語文と日本語文は\\nバイト対符号化 [12] により部分単語に分割した (32K\\n共通併合操作)。翻訳には、注意付き符号器復号器モ\\nデル [8] を実装した OpenNMT-lua 2をデフォールト\\n設定で使用し、翻訳精度 BLEU[9] は Moses toolkit の\\nmulti-bleu.perl で測定した。\\nDataset\\n| 1-to-1 | 2-to-2\\nIWSLT2017\\n12.19 12.26\\nOpenSubtitles 2018 12.23 | 12.67\\nGlobal Voices\\n10.66 10.80\\nHiraganaTimes_books 12.91 13.23\\nHiragana Times\\n13.23 13.32\\nWikipedia_Kyoto\\n9.36 9.64\\nNICT-align\\n23.09 23.12\\nYomiuri Editorial 14.53 15.26\\nAll\\n12.77 | 13.02\\n表 2: 各データに対する 1-to-1 と 2-to-2 の翻訳精度\\n-3-\\nCopyright(C) 2019 The Association for Natural Language Processing.\\nAll Rights Reserved.\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['responses'][2]['fullTextAnnotation']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.2 - 翻訳精度と文脈翻訳テスト\\n参考文献\\n[1] Rachel Bawden, Rico Sennrich, , Alexandra Birch, and Barry\\nHaddow. Evaluating Discourse Phenomena in Neural Ma-\\nchine Translation. In Proceedings of the NAACL-2018, pp.\\n1304-1313, 2018.\\n訓練データから 1-to-1 と 2-to-2 のモデルを作成し、\\n各データのテストセットで翻訳精度 (BLEU)を測定し\\nた結果を表2に示す。 2-to-2 の翻訳精度は 1-to-1 に比\\nべて一貫して良いがその差は小さい。\\nOpenNMT-lua の -tgt オプションを使って、正解文\\n対と不正解文対を強制翻訳 (forced decoding) し、正\\n解文対の対数確率が不正解文対より高いテストの割合\\nを文脈翻訳テストの正解率とする。表3に各テストに\\n対する 1-to-1 と 2-to-2 の正解率を示す。\\n[2] Alastair Butler, Tomoko Hotta, Ruriko Otomo, Kei Yoshi-\\nmoto, Zhen Zhou, and Hong Zhu. Keyaki treebank: Phrase\\nstructure with functional information for japanese. In Pro-\\nceedings of Text Annotation Workshop, 2012.\\n[3] Mauro Cettolo, Marcello Federico, Luisa Bentivogli, Jan\\nNiehues, Sebastian Stüker, Katsuhito Sudoh, Koichiro\\nYoshino, and Christian Federmann. Overview of the iwslt\\n2017 evaluation campaign. In Proceedings of the IWSLT-\\n2017, pp. 2-14, 2017.\\n[4] Robert Dale, Ilya Anisimoff, and George Narroway. Hoo\\n2012: A report on the preposition and determiner error cor-\\nrection shared task. In Proceedings of the Seventh Workshop\\non Building Educational Applications Using NLP, pp. 54–\\n62, 2012.\\nテスト カ テゴリ\\n共参照冠詞\\n代名詞\\n一貫性 曖昧性\\n对 1\\ntests | 1-to-1 | 2-to-2\\n330 0.76 0.75\\n220 | 0.53 | 0.70\\n0.50 0.52\\n73 0.49 | 0.50\\n378\\n[5] Eduard Hovy, Mitchell Marcus, Martha Palmer, Lance\\nRamshaw, and Ralph Weischedel. Ontonotes: The 90% solu-\\ntion. In Proceedings of the NAACL-2006, pp. 57-60, 2006.\\n表 3: 各テストに対する 1-to-1 と 2-to-2 の正解率\\n[6] Taku Kudo, Hiroshi Ichikawa, and Hideto Kazawa. A joint\\ninference of deep case analysis and zero subject generation for\\njapanese-to-english statistical machine translation. In Pro-\\nceedings of the ACL-2014, pp.557-562, 2014.\\n[7] Pierre Lison, Jörg Tiedemann, and Milen Kouylekov. Open-\\nsubtitles 2018: Statistical rescoring of sentence alignments in\\nlarge, noisy parallel corpora. In Proceedings of the LREC-\\n2018, pp. 1742-1748, 2018.\\n[8] Thang Luong, Hieu Pham, and Christopher D. Manning.\\nEffective Approaches to Attention-based Neural Machine\\nTranslation. In Proceedings of the EMNLP-2015, pp. 1412-\\n1421, 2015.\\n代名詞翻訳に関して 2-to-2 は 1-to-1 より大幅に正\\n解率が高いが、その他のカテゴリでは両者に大差はな\\nい。冠詞の正解率 (約 75%) は設計上のベースライン\\n(約 50%) より大幅に高い。これは、代名詞や曖昧性に\\nおいては、多義のそれぞれについてそれが正解となる\\n先行文脈を作成し、正解と不正解を入れ替えると、正\\n解率が50%になるようにテストを作成できるが、冠詞\\nに関してはこのような先行文脈を複数用意することが\\n難しいことと、一文の中だけで言語モデルが正解を出\\nしてしまうことが原因だと思われる。\\n[9] Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing\\nZhu. Bleu: a Method for Automatic Evaluation of Machine\\nTranslation. In Proceedings of the ACL-2002, pp. 311-318,\\n2002.\\n[10] Prokopis Prokopidis, Vassilis Papavassiliou, and Stelios\\nPiperidis. Parallel global voices: a collection of multilin-\\ngual corpora with citizen media stories. In Proceedings of\\nthe LREC-2016, pp. 900-905, 2016.\\n[11] Rico Sennrich. How grammatical is character-level neural\\nmachine translation? assessing mt quality with contrastive\\ntranslation pairs. In Proceedings of the EACL-2017, pp.\\n376-382, 2017.\\n4 おわりに\\n(12) Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural\\nmachine translation of rare words with subword units. In\\nProceedings of the ACL-2016, pp. 1715-1725, 2016.\\n[13] Hirotoshi Taira, Katsuhito Sudoh, and Masaaki Nagata. Zero\\npronoun resolution can improve the quality of j-e translation.\\nIn Proceedings of the Sixth Workshop on Syntar, Semantics\\nand Structure in Statistical Translation (SSST-2012), pp.\\n111-118, 2012.\\nルールベース翻訳や統計的機械翻訳では、日本語か\\nら英語への翻訳において日本語のゼロ代名詞は最も難\\nしい問題とされ、様々な手法が提案された [13, 6, 141。\\n本研究で提案した日英文脈翻訳テストにより、ニュー\\nラル機械翻訳では、一般的な文脈翻訳の枠組みを用い\\nて日本語のゼロ代名詞を英語へ翻訳する精度を大きく\\n改善できる見通しが得られた。\\n今後は、英語から日本語への文脈翻訳テストの作成\\n法、および、文脈翻訳において一貫性を改善する手法\\nを検討したい。\\n[14] Shunsuke Takeno, Masaaki Nagata, and Kazuhide Ya-\\nmamoto. Integrating empty category detection into preorder-\\ning machine translation. In Proceedings of the 3rd Workshop\\non Asian Translation (WAT-2016), pp. 157-165, 2016.\\n(15) Jörg Tiedemann and Yves Scherrer. Neural machine trans-\\nlation with extended context. In Proceedings of the Third\\nWorkshop on Discourse in Machine Translation, pp. 82–92,\\n2017.\\n[16] Masao Utiyama and Mayumi Takahashi. English-japanese\\ntranslation alignment data.\\n[17] Elena Voita, Pavel Serdyukov, Rico Sennrich, and Ivan Titov.\\nContext-aware neural machine translation learns anaphora\\nresolution. In Proceedings of the ACL-2018, pp. 1264-1274,\\n2018.\\nhttps://alaginrc.nict.go.jp/WikiCorpus/index\\\\_E.\\nhtml\\n2http://opennmt.net/\\n-4-\\nCopyright(C) 2019 The Association for Natural Language Processing.\\nAll Rights Reserved.\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['responses'][3]['fullTextAnnotation']['text']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
